{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/PatrickChen/anaconda/envs/dsienv/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# http://localhost:8888/notebooks/Desktop/DSI-ATX-1/curriculum/04-lessons/week-05/2.4-lab/code/solution-code/solution-code-2_4.ipynb\n",
    "# http://localhost:8888/notebooks/Desktop/DSI-ATX-1/curriculum/04-lessons/week-05/2.3-lab/code/solution-code/solution-code-2_3.ipynb#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Task: Describe the goals of your study"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "survival        Survival\n",
    "                (0 = No; 1 = Yes)\n",
    "pclass          Passenger Class\n",
    "                (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "name            Name\n",
    "sex             Sex\n",
    "age             Age\n",
    "sibsp           Number of Siblings/Spouses Aboard\n",
    "parch           Number of Parents/Children Aboard\n",
    "ticket          Ticket Number\n",
    "fare            Passenger Fare\n",
    "cabin           Cabin\n",
    "embarked        Port of Embarkation\n",
    "                (C = Cherbourg; Q = Queenstown; S = Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Aquire the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Connect to the remote database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com/titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Query the database and aggregate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * FROM train', engine)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What are the risks and assumptions of our data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all data is collected for every column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Describe the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index            int64\n",
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  PassengerId  Survived  Pclass  \\\n",
       "1       1            2         1       1   \n",
       "3       3            4         1       1   \n",
       "6       6            7         0       1   \n",
       "10     10           11         1       3   \n",
       "11     11           12         1       1   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "\n",
       "    Parch    Ticket     Fare Cabin Embarked  \n",
       "1       0  PC 17599  71.2833   C85        C  \n",
       "3       0    113803  53.1000  C123        S  \n",
       "6       0     17463  51.8625   E46        S  \n",
       "10      1   PP 9549  16.7000    G6        S  \n",
       "11      0    113783  26.5500  C103        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.Cabin = df.Cabin.apply(lambda x:x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create Dummy Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.concat([df.Survived,df.Age,df.Fare],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>51.8625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>26.5500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived   Age     Fare\n",
       "1          1  38.0  71.2833\n",
       "3          1  35.0  53.1000\n",
       "6          0  54.0  51.8625\n",
       "10         1   4.0  16.7000\n",
       "11         1  58.0  26.5500"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating dummies [df.Sex,df.Pclass,df.Cabin,df.Embarked]\n",
    "def dummies(col):\n",
    "    x = pd.get_dummies(col)\n",
    "    pd.concat([df2,x], axis=1) \n",
    "    \n",
    "dummies(df.Sex)\n",
    "dummies(df.Pclass)\n",
    "dummies(df.Cabin)\n",
    "dummies(df.Embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scaling \n",
    "from sklearn import preprocessing\n",
    "for i in df2.columns:\n",
    "    df2[i]=preprocessing.scale(df2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>T</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.698430</td>\n",
       "      <td>0.149065</td>\n",
       "      <td>-0.097180</td>\n",
       "      <td>1.039012</td>\n",
       "      <td>-1.039012</td>\n",
       "      <td>0.397779</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>-0.240424</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>1.608799</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>-0.149487</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>1.347362</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>-1.315805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698430</td>\n",
       "      <td>-0.043230</td>\n",
       "      <td>-0.335997</td>\n",
       "      <td>1.039012</td>\n",
       "      <td>-1.039012</td>\n",
       "      <td>0.397779</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>-0.240424</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>1.608799</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>-0.149487</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>-0.742191</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>0.759991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.431782</td>\n",
       "      <td>1.174636</td>\n",
       "      <td>-0.352250</td>\n",
       "      <td>-0.962453</td>\n",
       "      <td>0.962453</td>\n",
       "      <td>0.397779</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>-0.240424</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>-0.621582</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>2.258318</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>-0.149487</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>-0.742191</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>0.759991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.698430</td>\n",
       "      <td>-2.030273</td>\n",
       "      <td>-0.814070</td>\n",
       "      <td>1.039012</td>\n",
       "      <td>-1.039012</td>\n",
       "      <td>-2.513961</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>4.159327</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>-0.621582</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>6.689544</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>-0.742191</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>0.759991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.698430</td>\n",
       "      <td>1.431029</td>\n",
       "      <td>-0.684702</td>\n",
       "      <td>1.039012</td>\n",
       "      <td>-1.039012</td>\n",
       "      <td>0.397779</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>-0.240424</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>1.608799</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>-0.149487</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>-0.742191</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>0.759991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived       Age      Fare    female      male         1         2  \\\n",
       "1   0.698430  0.149065 -0.097180  1.039012 -1.039012  0.397779 -0.298807   \n",
       "3   0.698430 -0.043230 -0.335997  1.039012 -1.039012  0.397779 -0.298807   \n",
       "6  -1.431782  1.174636 -0.352250 -0.962453  0.962453  0.397779 -0.298807   \n",
       "10  0.698430 -2.030273 -0.814070  1.039012 -1.039012 -2.513961 -0.298807   \n",
       "11  0.698430  1.431029 -0.684702  1.039012 -1.039012  0.397779 -0.298807   \n",
       "\n",
       "           3         A         B         C         D         E        F  \\\n",
       "1  -0.240424 -0.264906 -0.554205  1.608799 -0.451605 -0.442807 -0.25289   \n",
       "3  -0.240424 -0.264906 -0.554205  1.608799 -0.451605 -0.442807 -0.25289   \n",
       "6  -0.240424 -0.264906 -0.554205 -0.621582 -0.451605  2.258318 -0.25289   \n",
       "10  4.159327 -0.264906 -0.554205 -0.621582 -0.451605 -0.442807 -0.25289   \n",
       "11 -0.240424 -0.264906 -0.554205  1.608799 -0.451605 -0.442807 -0.25289   \n",
       "\n",
       "           G         T         C         Q         S  \n",
       "1  -0.149487 -0.074125  1.347362 -0.105118 -1.315805  \n",
       "3  -0.149487 -0.074125 -0.742191 -0.105118  0.759991  \n",
       "6  -0.149487 -0.074125 -0.742191 -0.105118  0.759991  \n",
       "10  6.689544 -0.074125 -0.742191 -0.105118  0.759991  \n",
       "11 -0.149487 -0.074125 -0.742191 -0.105118  0.759991  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Logistic Regression and Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define the variables that we will use in our classification analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>T</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.149065</td>\n",
       "      <td>-0.097180</td>\n",
       "      <td>1.039012</td>\n",
       "      <td>-1.039012</td>\n",
       "      <td>0.397779</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>-0.240424</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>1.608799</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>-0.149487</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>1.347362</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>-1.315805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.043230</td>\n",
       "      <td>-0.335997</td>\n",
       "      <td>1.039012</td>\n",
       "      <td>-1.039012</td>\n",
       "      <td>0.397779</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>-0.240424</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>1.608799</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>-0.149487</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>-0.742191</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>0.759991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.174636</td>\n",
       "      <td>-0.352250</td>\n",
       "      <td>-0.962453</td>\n",
       "      <td>0.962453</td>\n",
       "      <td>0.397779</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>-0.240424</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>-0.621582</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>2.258318</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>-0.149487</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>-0.742191</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>0.759991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-2.030273</td>\n",
       "      <td>-0.814070</td>\n",
       "      <td>1.039012</td>\n",
       "      <td>-1.039012</td>\n",
       "      <td>-2.513961</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>4.159327</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>-0.621582</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>6.689544</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>-0.742191</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>0.759991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.431029</td>\n",
       "      <td>-0.684702</td>\n",
       "      <td>1.039012</td>\n",
       "      <td>-1.039012</td>\n",
       "      <td>0.397779</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>-0.240424</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>1.608799</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>-0.149487</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>-0.742191</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>0.759991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age      Fare    female      male         1         2         3  \\\n",
       "1   0.149065 -0.097180  1.039012 -1.039012  0.397779 -0.298807 -0.240424   \n",
       "3  -0.043230 -0.335997  1.039012 -1.039012  0.397779 -0.298807 -0.240424   \n",
       "6   1.174636 -0.352250 -0.962453  0.962453  0.397779 -0.298807 -0.240424   \n",
       "10 -2.030273 -0.814070  1.039012 -1.039012 -2.513961 -0.298807  4.159327   \n",
       "11  1.431029 -0.684702  1.039012 -1.039012  0.397779 -0.298807 -0.240424   \n",
       "\n",
       "           A         B         C         D         E        F         G  \\\n",
       "1  -0.264906 -0.554205  1.608799 -0.451605 -0.442807 -0.25289 -0.149487   \n",
       "3  -0.264906 -0.554205  1.608799 -0.451605 -0.442807 -0.25289 -0.149487   \n",
       "6  -0.264906 -0.554205 -0.621582 -0.451605  2.258318 -0.25289 -0.149487   \n",
       "10 -0.264906 -0.554205 -0.621582 -0.451605 -0.442807 -0.25289  6.689544   \n",
       "11 -0.264906 -0.554205  1.608799 -0.451605 -0.442807 -0.25289 -0.149487   \n",
       "\n",
       "           T         C         Q         S  \n",
       "1  -0.074125  1.347362 -0.105118 -1.315805  \n",
       "3  -0.074125 -0.742191 -0.105118  0.759991  \n",
       "6  -0.074125 -0.742191 -0.105118  0.759991  \n",
       "10 -0.074125 -0.742191 -0.105118  0.759991  \n",
       "11 -0.074125 -0.742191 -0.105118  0.759991  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "X = df2.iloc[:,1:]\n",
    "y = df[u'Survived']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Transform \"Y\" into a 1-Dimensional Array for SciKit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#????????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Conduct the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Examine the coefficients to see our correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>T</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.254085</td>\n",
       "      <td>0.134241</td>\n",
       "      <td>0.532418</td>\n",
       "      <td>-0.532418</td>\n",
       "      <td>-0.006668</td>\n",
       "      <td>0.081391</td>\n",
       "      <td>-0.088158</td>\n",
       "      <td>-0.050109</td>\n",
       "      <td>0.085066</td>\n",
       "      <td>-0.111087</td>\n",
       "      <td>0.067153</td>\n",
       "      <td>0.057730</td>\n",
       "      <td>-0.019268</td>\n",
       "      <td>-0.054813</td>\n",
       "      <td>-0.106131</td>\n",
       "      <td>0.104870</td>\n",
       "      <td>-0.038544</td>\n",
       "      <td>-0.095861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.254085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.092424</td>\n",
       "      <td>-0.184969</td>\n",
       "      <td>0.184969</td>\n",
       "      <td>0.308880</td>\n",
       "      <td>-0.199340</td>\n",
       "      <td>-0.226143</td>\n",
       "      <td>0.155518</td>\n",
       "      <td>-0.050394</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>0.097199</td>\n",
       "      <td>0.069318</td>\n",
       "      <td>-0.254816</td>\n",
       "      <td>-0.200495</td>\n",
       "      <td>0.044308</td>\n",
       "      <td>0.085018</td>\n",
       "      <td>0.019038</td>\n",
       "      <td>-0.088568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.134241</td>\n",
       "      <td>-0.092424</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.130433</td>\n",
       "      <td>-0.130433</td>\n",
       "      <td>0.330206</td>\n",
       "      <td>-0.236404</td>\n",
       "      <td>-0.213634</td>\n",
       "      <td>-0.138541</td>\n",
       "      <td>0.278442</td>\n",
       "      <td>0.220260</td>\n",
       "      <td>-0.120913</td>\n",
       "      <td>-0.185130</td>\n",
       "      <td>-0.197038</td>\n",
       "      <td>-0.127816</td>\n",
       "      <td>-0.042040</td>\n",
       "      <td>0.240382</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>-0.242172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.532418</td>\n",
       "      <td>-0.184969</td>\n",
       "      <td>0.130433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.062995</td>\n",
       "      <td>0.071243</td>\n",
       "      <td>0.009203</td>\n",
       "      <td>-0.210777</td>\n",
       "      <td>0.085704</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>0.061023</td>\n",
       "      <td>-0.042134</td>\n",
       "      <td>-0.059340</td>\n",
       "      <td>0.155319</td>\n",
       "      <td>-0.071342</td>\n",
       "      <td>0.062691</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>-0.063146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>-0.532418</td>\n",
       "      <td>0.184969</td>\n",
       "      <td>-0.130433</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062995</td>\n",
       "      <td>-0.071243</td>\n",
       "      <td>-0.009203</td>\n",
       "      <td>0.210777</td>\n",
       "      <td>-0.085704</td>\n",
       "      <td>-0.011597</td>\n",
       "      <td>-0.061023</td>\n",
       "      <td>0.042134</td>\n",
       "      <td>0.059340</td>\n",
       "      <td>-0.155319</td>\n",
       "      <td>0.071342</td>\n",
       "      <td>-0.062691</td>\n",
       "      <td>-0.004024</td>\n",
       "      <td>0.063146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006668</td>\n",
       "      <td>0.308880</td>\n",
       "      <td>0.330206</td>\n",
       "      <td>-0.062995</td>\n",
       "      <td>0.062995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.751190</td>\n",
       "      <td>-0.604415</td>\n",
       "      <td>0.105374</td>\n",
       "      <td>0.220451</td>\n",
       "      <td>0.247252</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>-0.081729</td>\n",
       "      <td>-0.635756</td>\n",
       "      <td>-0.375805</td>\n",
       "      <td>0.029485</td>\n",
       "      <td>0.228733</td>\n",
       "      <td>0.041814</td>\n",
       "      <td>-0.236252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.081391</td>\n",
       "      <td>-0.199340</td>\n",
       "      <td>-0.236404</td>\n",
       "      <td>0.071243</td>\n",
       "      <td>-0.071243</td>\n",
       "      <td>-0.751190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.071840</td>\n",
       "      <td>-0.079156</td>\n",
       "      <td>-0.165600</td>\n",
       "      <td>-0.185733</td>\n",
       "      <td>0.077483</td>\n",
       "      <td>0.029109</td>\n",
       "      <td>0.594906</td>\n",
       "      <td>-0.044668</td>\n",
       "      <td>-0.022149</td>\n",
       "      <td>-0.138522</td>\n",
       "      <td>-0.031410</td>\n",
       "      <td>0.144389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.088158</td>\n",
       "      <td>-0.226143</td>\n",
       "      <td>-0.213634</td>\n",
       "      <td>0.009203</td>\n",
       "      <td>-0.009203</td>\n",
       "      <td>-0.604415</td>\n",
       "      <td>-0.071840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.063690</td>\n",
       "      <td>-0.133244</td>\n",
       "      <td>-0.149443</td>\n",
       "      <td>-0.108577</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>0.242650</td>\n",
       "      <td>0.621765</td>\n",
       "      <td>-0.017821</td>\n",
       "      <td>-0.178440</td>\n",
       "      <td>-0.025273</td>\n",
       "      <td>0.182720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>-0.050109</td>\n",
       "      <td>0.155518</td>\n",
       "      <td>-0.138541</td>\n",
       "      <td>-0.210777</td>\n",
       "      <td>0.210777</td>\n",
       "      <td>0.105374</td>\n",
       "      <td>-0.079156</td>\n",
       "      <td>-0.063690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.146812</td>\n",
       "      <td>-0.164661</td>\n",
       "      <td>-0.119633</td>\n",
       "      <td>-0.117303</td>\n",
       "      <td>-0.066992</td>\n",
       "      <td>-0.039600</td>\n",
       "      <td>-0.019636</td>\n",
       "      <td>0.126285</td>\n",
       "      <td>-0.027846</td>\n",
       "      <td>-0.119444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.085066</td>\n",
       "      <td>-0.050394</td>\n",
       "      <td>0.278442</td>\n",
       "      <td>0.085704</td>\n",
       "      <td>-0.085704</td>\n",
       "      <td>0.220451</td>\n",
       "      <td>-0.165600</td>\n",
       "      <td>-0.133244</td>\n",
       "      <td>-0.146812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.344483</td>\n",
       "      <td>-0.250282</td>\n",
       "      <td>-0.245406</td>\n",
       "      <td>-0.140153</td>\n",
       "      <td>-0.082846</td>\n",
       "      <td>-0.041080</td>\n",
       "      <td>0.154229</td>\n",
       "      <td>-0.058257</td>\n",
       "      <td>-0.140641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>-0.111087</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>0.220260</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>-0.011597</td>\n",
       "      <td>0.247252</td>\n",
       "      <td>-0.185733</td>\n",
       "      <td>-0.149443</td>\n",
       "      <td>-0.164661</td>\n",
       "      <td>-0.344483</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.280710</td>\n",
       "      <td>-0.275241</td>\n",
       "      <td>-0.157192</td>\n",
       "      <td>-0.092918</td>\n",
       "      <td>-0.046075</td>\n",
       "      <td>0.022545</td>\n",
       "      <td>0.169113</td>\n",
       "      <td>-0.058894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.067153</td>\n",
       "      <td>0.097199</td>\n",
       "      <td>-0.120913</td>\n",
       "      <td>0.061023</td>\n",
       "      <td>-0.061023</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>0.077483</td>\n",
       "      <td>-0.108577</td>\n",
       "      <td>-0.119633</td>\n",
       "      <td>-0.250282</td>\n",
       "      <td>-0.280710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.199974</td>\n",
       "      <td>-0.114207</td>\n",
       "      <td>-0.067509</td>\n",
       "      <td>-0.033475</td>\n",
       "      <td>0.060548</td>\n",
       "      <td>-0.047472</td>\n",
       "      <td>-0.049904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.057730</td>\n",
       "      <td>0.069318</td>\n",
       "      <td>-0.185130</td>\n",
       "      <td>-0.042134</td>\n",
       "      <td>0.042134</td>\n",
       "      <td>-0.081729</td>\n",
       "      <td>0.029109</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>-0.117303</td>\n",
       "      <td>-0.245406</td>\n",
       "      <td>-0.275241</td>\n",
       "      <td>-0.199974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.111982</td>\n",
       "      <td>-0.066194</td>\n",
       "      <td>-0.032823</td>\n",
       "      <td>-0.174436</td>\n",
       "      <td>-0.046547</td>\n",
       "      <td>0.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>-0.019268</td>\n",
       "      <td>-0.254816</td>\n",
       "      <td>-0.197038</td>\n",
       "      <td>-0.059340</td>\n",
       "      <td>0.059340</td>\n",
       "      <td>-0.635756</td>\n",
       "      <td>0.594906</td>\n",
       "      <td>0.242650</td>\n",
       "      <td>-0.066992</td>\n",
       "      <td>-0.140153</td>\n",
       "      <td>-0.157192</td>\n",
       "      <td>-0.114207</td>\n",
       "      <td>-0.111982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.037804</td>\n",
       "      <td>-0.018745</td>\n",
       "      <td>-0.187693</td>\n",
       "      <td>-0.026583</td>\n",
       "      <td>0.192194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>-0.054813</td>\n",
       "      <td>-0.200495</td>\n",
       "      <td>-0.127816</td>\n",
       "      <td>0.155319</td>\n",
       "      <td>-0.155319</td>\n",
       "      <td>-0.375805</td>\n",
       "      <td>-0.044668</td>\n",
       "      <td>0.621765</td>\n",
       "      <td>-0.039600</td>\n",
       "      <td>-0.082846</td>\n",
       "      <td>-0.092918</td>\n",
       "      <td>-0.067509</td>\n",
       "      <td>-0.066194</td>\n",
       "      <td>-0.037804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011081</td>\n",
       "      <td>-0.110948</td>\n",
       "      <td>-0.015714</td>\n",
       "      <td>0.113609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>-0.106131</td>\n",
       "      <td>0.044308</td>\n",
       "      <td>-0.042040</td>\n",
       "      <td>-0.071342</td>\n",
       "      <td>0.071342</td>\n",
       "      <td>0.029485</td>\n",
       "      <td>-0.022149</td>\n",
       "      <td>-0.017821</td>\n",
       "      <td>-0.019636</td>\n",
       "      <td>-0.041080</td>\n",
       "      <td>-0.046075</td>\n",
       "      <td>-0.033475</td>\n",
       "      <td>-0.032823</td>\n",
       "      <td>-0.018745</td>\n",
       "      <td>-0.011081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.055015</td>\n",
       "      <td>-0.007792</td>\n",
       "      <td>0.056334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.104870</td>\n",
       "      <td>0.085018</td>\n",
       "      <td>0.240382</td>\n",
       "      <td>0.062691</td>\n",
       "      <td>-0.062691</td>\n",
       "      <td>0.228733</td>\n",
       "      <td>-0.138522</td>\n",
       "      <td>-0.178440</td>\n",
       "      <td>0.126285</td>\n",
       "      <td>0.154229</td>\n",
       "      <td>0.022545</td>\n",
       "      <td>0.060548</td>\n",
       "      <td>-0.174436</td>\n",
       "      <td>-0.187693</td>\n",
       "      <td>-0.110948</td>\n",
       "      <td>-0.055015</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.078017</td>\n",
       "      <td>-0.976579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>-0.038544</td>\n",
       "      <td>0.019038</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>-0.004024</td>\n",
       "      <td>0.041814</td>\n",
       "      <td>-0.031410</td>\n",
       "      <td>-0.025273</td>\n",
       "      <td>-0.027846</td>\n",
       "      <td>-0.058257</td>\n",
       "      <td>0.169113</td>\n",
       "      <td>-0.047472</td>\n",
       "      <td>-0.046547</td>\n",
       "      <td>-0.026583</td>\n",
       "      <td>-0.015714</td>\n",
       "      <td>-0.007792</td>\n",
       "      <td>-0.078017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.138314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>-0.095861</td>\n",
       "      <td>-0.088568</td>\n",
       "      <td>-0.242172</td>\n",
       "      <td>-0.063146</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>-0.236252</td>\n",
       "      <td>0.144389</td>\n",
       "      <td>0.182720</td>\n",
       "      <td>-0.119444</td>\n",
       "      <td>-0.140641</td>\n",
       "      <td>-0.058894</td>\n",
       "      <td>-0.049904</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.192194</td>\n",
       "      <td>0.113609</td>\n",
       "      <td>0.056334</td>\n",
       "      <td>-0.976579</td>\n",
       "      <td>-0.138314</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived       Age      Fare    female      male         1  \\\n",
       "Survived  1.000000 -0.254085  0.134241  0.532418 -0.532418 -0.006668   \n",
       "Age      -0.254085  1.000000 -0.092424 -0.184969  0.184969  0.308880   \n",
       "Fare      0.134241 -0.092424  1.000000  0.130433 -0.130433  0.330206   \n",
       "female    0.532418 -0.184969  0.130433  1.000000 -1.000000 -0.062995   \n",
       "male     -0.532418  0.184969 -0.130433 -1.000000  1.000000  0.062995   \n",
       "1        -0.006668  0.308880  0.330206 -0.062995  0.062995  1.000000   \n",
       "2         0.081391 -0.199340 -0.236404  0.071243 -0.071243 -0.751190   \n",
       "3        -0.088158 -0.226143 -0.213634  0.009203 -0.009203 -0.604415   \n",
       "A        -0.050109  0.155518 -0.138541 -0.210777  0.210777  0.105374   \n",
       "B         0.085066 -0.050394  0.278442  0.085704 -0.085704  0.220451   \n",
       "C        -0.111087  0.016425  0.220260  0.011597 -0.011597  0.247252   \n",
       "D         0.067153  0.097199 -0.120913  0.061023 -0.061023  0.009967   \n",
       "E         0.057730  0.069318 -0.185130 -0.042134  0.042134 -0.081729   \n",
       "F        -0.019268 -0.254816 -0.197038 -0.059340  0.059340 -0.635756   \n",
       "G        -0.054813 -0.200495 -0.127816  0.155319 -0.155319 -0.375805   \n",
       "T        -0.106131  0.044308 -0.042040 -0.071342  0.071342  0.029485   \n",
       "C         0.104870  0.085018  0.240382  0.062691 -0.062691  0.228733   \n",
       "Q        -0.038544  0.019038  0.015625  0.004024 -0.004024  0.041814   \n",
       "S        -0.095861 -0.088568 -0.242172 -0.063146  0.063146 -0.236252   \n",
       "\n",
       "                 2         3         A         B         C         D  \\\n",
       "Survived  0.081391 -0.088158 -0.050109  0.085066 -0.111087  0.067153   \n",
       "Age      -0.199340 -0.226143  0.155518 -0.050394  0.016425  0.097199   \n",
       "Fare     -0.236404 -0.213634 -0.138541  0.278442  0.220260 -0.120913   \n",
       "female    0.071243  0.009203 -0.210777  0.085704  0.011597  0.061023   \n",
       "male     -0.071243 -0.009203  0.210777 -0.085704 -0.011597 -0.061023   \n",
       "1        -0.751190 -0.604415  0.105374  0.220451  0.247252  0.009967   \n",
       "2         1.000000 -0.071840 -0.079156 -0.165600 -0.185733  0.077483   \n",
       "3        -0.071840  1.000000 -0.063690 -0.133244 -0.149443 -0.108577   \n",
       "A        -0.079156 -0.063690  1.000000 -0.146812 -0.164661 -0.119633   \n",
       "B        -0.165600 -0.133244 -0.146812  1.000000 -0.344483 -0.250282   \n",
       "C        -0.185733 -0.149443 -0.164661 -0.344483  1.000000 -0.280710   \n",
       "D         0.077483 -0.108577 -0.119633 -0.250282 -0.280710  1.000000   \n",
       "E         0.029109  0.088363 -0.117303 -0.245406 -0.275241 -0.199974   \n",
       "F         0.594906  0.242650 -0.066992 -0.140153 -0.157192 -0.114207   \n",
       "G        -0.044668  0.621765 -0.039600 -0.082846 -0.092918 -0.067509   \n",
       "T        -0.022149 -0.017821 -0.019636 -0.041080 -0.046075 -0.033475   \n",
       "C        -0.138522 -0.178440  0.126285  0.154229  0.022545  0.060548   \n",
       "Q        -0.031410 -0.025273 -0.027846 -0.058257  0.169113 -0.047472   \n",
       "S         0.144389  0.182720 -0.119444 -0.140641 -0.058894 -0.049904   \n",
       "\n",
       "                 E         F         G         T         C         Q         S  \n",
       "Survived  0.057730 -0.019268 -0.054813 -0.106131  0.104870 -0.038544 -0.095861  \n",
       "Age       0.069318 -0.254816 -0.200495  0.044308  0.085018  0.019038 -0.088568  \n",
       "Fare     -0.185130 -0.197038 -0.127816 -0.042040  0.240382  0.015625 -0.242172  \n",
       "female   -0.042134 -0.059340  0.155319 -0.071342  0.062691  0.004024 -0.063146  \n",
       "male      0.042134  0.059340 -0.155319  0.071342 -0.062691 -0.004024  0.063146  \n",
       "1        -0.081729 -0.635756 -0.375805  0.029485  0.228733  0.041814 -0.236252  \n",
       "2         0.029109  0.594906 -0.044668 -0.022149 -0.138522 -0.031410  0.144389  \n",
       "3         0.088363  0.242650  0.621765 -0.017821 -0.178440 -0.025273  0.182720  \n",
       "A        -0.117303 -0.066992 -0.039600 -0.019636  0.126285 -0.027846 -0.119444  \n",
       "B        -0.245406 -0.140153 -0.082846 -0.041080  0.154229 -0.058257 -0.140641  \n",
       "C        -0.275241 -0.157192 -0.092918 -0.046075  0.022545  0.169113 -0.058894  \n",
       "D        -0.199974 -0.114207 -0.067509 -0.033475  0.060548 -0.047472 -0.049904  \n",
       "E         1.000000 -0.111982 -0.066194 -0.032823 -0.174436 -0.046547  0.183333  \n",
       "F        -0.111982  1.000000 -0.037804 -0.018745 -0.187693 -0.026583  0.192194  \n",
       "G        -0.066194 -0.037804  1.000000 -0.011081 -0.110948 -0.015714  0.113609  \n",
       "T        -0.032823 -0.018745 -0.011081  1.000000 -0.055015 -0.007792  0.056334  \n",
       "C        -0.174436 -0.187693 -0.110948 -0.055015  1.000000 -0.078017 -0.976579  \n",
       "Q        -0.046547 -0.026583 -0.015714 -0.007792 -0.078017  1.000000 -0.138314  \n",
       "S         0.183333  0.192194  0.113609  0.056334 -0.976579 -0.138314  1.000000  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Test the Model by introducing a *Test* or *Validaton* set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=5, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=5)\n",
    "logreg.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Predict the class labels for the *Test* set   ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Predict the class probabilities for the *Test* set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35486196,  0.64513804],\n",
       "       [ 0.73421042,  0.26578958],\n",
       "       [ 0.02842001,  0.97157999],\n",
       "       [ 0.17108434,  0.82891566],\n",
       "       [ 0.0128808 ,  0.9871192 ],\n",
       "       [ 0.03451531,  0.96548469],\n",
       "       [ 0.16430174,  0.83569826],\n",
       "       [ 0.39908285,  0.60091715],\n",
       "       [ 0.10781854,  0.89218146],\n",
       "       [ 0.70816109,  0.29183891],\n",
       "       [ 0.32254387,  0.67745613],\n",
       "       [ 0.59388076,  0.40611924],\n",
       "       [ 0.45135779,  0.54864221],\n",
       "       [ 0.02008495,  0.97991505],\n",
       "       [ 0.90466176,  0.09533824],\n",
       "       [ 0.69857042,  0.30142958],\n",
       "       [ 0.36472454,  0.63527546],\n",
       "       [ 0.12673852,  0.87326148],\n",
       "       [ 0.42402205,  0.57597795],\n",
       "       [ 0.12245459,  0.87754541],\n",
       "       [ 0.10887793,  0.89112207],\n",
       "       [ 0.71814378,  0.28185622],\n",
       "       [ 0.70196854,  0.29803146],\n",
       "       [ 0.42449716,  0.57550284],\n",
       "       [ 0.08727287,  0.91272713],\n",
       "       [ 0.01359177,  0.98640823],\n",
       "       [ 0.0615398 ,  0.9384602 ],\n",
       "       [ 0.4208022 ,  0.5791978 ],\n",
       "       [ 0.47517246,  0.52482754],\n",
       "       [ 0.02988734,  0.97011266],\n",
       "       [ 0.2632627 ,  0.7367373 ],\n",
       "       [ 0.03555181,  0.96444819],\n",
       "       [ 0.22750442,  0.77249558],\n",
       "       [ 0.6175465 ,  0.3824535 ],\n",
       "       [ 0.49588445,  0.50411555],\n",
       "       [ 0.78544291,  0.21455709],\n",
       "       [ 0.13551127,  0.86448873],\n",
       "       [ 0.0097366 ,  0.9902634 ],\n",
       "       [ 0.12468183,  0.87531817],\n",
       "       [ 0.04526533,  0.95473467],\n",
       "       [ 0.43377909,  0.56622091],\n",
       "       [ 0.05230564,  0.94769436],\n",
       "       [ 0.74432976,  0.25567024],\n",
       "       [ 0.50163589,  0.49836411],\n",
       "       [ 0.37067608,  0.62932392],\n",
       "       [ 0.84335425,  0.15664575],\n",
       "       [ 0.64512373,  0.35487627],\n",
       "       [ 0.58470834,  0.41529166],\n",
       "       [ 0.02713163,  0.97286837],\n",
       "       [ 0.0352239 ,  0.9647761 ],\n",
       "       [ 0.61968888,  0.38031112],\n",
       "       [ 0.44376054,  0.55623946],\n",
       "       [ 0.45399035,  0.54600965],\n",
       "       [ 0.03545811,  0.96454189],\n",
       "       [ 0.88021029,  0.11978971],\n",
       "       [ 0.02779165,  0.97220835],\n",
       "       [ 0.24497879,  0.75502121],\n",
       "       [ 0.01163462,  0.98836538],\n",
       "       [ 0.06465117,  0.93534883],\n",
       "       [ 0.3930714 ,  0.6069286 ],\n",
       "       [ 0.59007424,  0.40992576]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Evaluate the *Test* set ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Cross validate the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.689743589744\n"
     ]
    }
   ],
   "source": [
    "# use cross-validation for find score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# Perform 6-fold cross validation\n",
    "scores = cross_val_score(logreg,X_test, Y_test, cv=5, scoring = 'accuracy')\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>T</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.254085</td>\n",
       "      <td>0.134241</td>\n",
       "      <td>0.532418</td>\n",
       "      <td>-0.532418</td>\n",
       "      <td>-0.006668</td>\n",
       "      <td>0.081391</td>\n",
       "      <td>-0.088158</td>\n",
       "      <td>-0.050109</td>\n",
       "      <td>0.085066</td>\n",
       "      <td>-0.111087</td>\n",
       "      <td>0.067153</td>\n",
       "      <td>0.057730</td>\n",
       "      <td>-0.019268</td>\n",
       "      <td>-0.054813</td>\n",
       "      <td>-0.106131</td>\n",
       "      <td>0.104870</td>\n",
       "      <td>-0.038544</td>\n",
       "      <td>-0.095861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.254085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.092424</td>\n",
       "      <td>-0.184969</td>\n",
       "      <td>0.184969</td>\n",
       "      <td>0.308880</td>\n",
       "      <td>-0.199340</td>\n",
       "      <td>-0.226143</td>\n",
       "      <td>0.155518</td>\n",
       "      <td>-0.050394</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>0.097199</td>\n",
       "      <td>0.069318</td>\n",
       "      <td>-0.254816</td>\n",
       "      <td>-0.200495</td>\n",
       "      <td>0.044308</td>\n",
       "      <td>0.085018</td>\n",
       "      <td>0.019038</td>\n",
       "      <td>-0.088568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.134241</td>\n",
       "      <td>-0.092424</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.130433</td>\n",
       "      <td>-0.130433</td>\n",
       "      <td>0.330206</td>\n",
       "      <td>-0.236404</td>\n",
       "      <td>-0.213634</td>\n",
       "      <td>-0.138541</td>\n",
       "      <td>0.278442</td>\n",
       "      <td>0.220260</td>\n",
       "      <td>-0.120913</td>\n",
       "      <td>-0.185130</td>\n",
       "      <td>-0.197038</td>\n",
       "      <td>-0.127816</td>\n",
       "      <td>-0.042040</td>\n",
       "      <td>0.240382</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>-0.242172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.532418</td>\n",
       "      <td>-0.184969</td>\n",
       "      <td>0.130433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.062995</td>\n",
       "      <td>0.071243</td>\n",
       "      <td>0.009203</td>\n",
       "      <td>-0.210777</td>\n",
       "      <td>0.085704</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>0.061023</td>\n",
       "      <td>-0.042134</td>\n",
       "      <td>-0.059340</td>\n",
       "      <td>0.155319</td>\n",
       "      <td>-0.071342</td>\n",
       "      <td>0.062691</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>-0.063146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>-0.532418</td>\n",
       "      <td>0.184969</td>\n",
       "      <td>-0.130433</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062995</td>\n",
       "      <td>-0.071243</td>\n",
       "      <td>-0.009203</td>\n",
       "      <td>0.210777</td>\n",
       "      <td>-0.085704</td>\n",
       "      <td>-0.011597</td>\n",
       "      <td>-0.061023</td>\n",
       "      <td>0.042134</td>\n",
       "      <td>0.059340</td>\n",
       "      <td>-0.155319</td>\n",
       "      <td>0.071342</td>\n",
       "      <td>-0.062691</td>\n",
       "      <td>-0.004024</td>\n",
       "      <td>0.063146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006668</td>\n",
       "      <td>0.308880</td>\n",
       "      <td>0.330206</td>\n",
       "      <td>-0.062995</td>\n",
       "      <td>0.062995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.751190</td>\n",
       "      <td>-0.604415</td>\n",
       "      <td>0.105374</td>\n",
       "      <td>0.220451</td>\n",
       "      <td>0.247252</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>-0.081729</td>\n",
       "      <td>-0.635756</td>\n",
       "      <td>-0.375805</td>\n",
       "      <td>0.029485</td>\n",
       "      <td>0.228733</td>\n",
       "      <td>0.041814</td>\n",
       "      <td>-0.236252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.081391</td>\n",
       "      <td>-0.199340</td>\n",
       "      <td>-0.236404</td>\n",
       "      <td>0.071243</td>\n",
       "      <td>-0.071243</td>\n",
       "      <td>-0.751190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.071840</td>\n",
       "      <td>-0.079156</td>\n",
       "      <td>-0.165600</td>\n",
       "      <td>-0.185733</td>\n",
       "      <td>0.077483</td>\n",
       "      <td>0.029109</td>\n",
       "      <td>0.594906</td>\n",
       "      <td>-0.044668</td>\n",
       "      <td>-0.022149</td>\n",
       "      <td>-0.138522</td>\n",
       "      <td>-0.031410</td>\n",
       "      <td>0.144389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.088158</td>\n",
       "      <td>-0.226143</td>\n",
       "      <td>-0.213634</td>\n",
       "      <td>0.009203</td>\n",
       "      <td>-0.009203</td>\n",
       "      <td>-0.604415</td>\n",
       "      <td>-0.071840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.063690</td>\n",
       "      <td>-0.133244</td>\n",
       "      <td>-0.149443</td>\n",
       "      <td>-0.108577</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>0.242650</td>\n",
       "      <td>0.621765</td>\n",
       "      <td>-0.017821</td>\n",
       "      <td>-0.178440</td>\n",
       "      <td>-0.025273</td>\n",
       "      <td>0.182720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>-0.050109</td>\n",
       "      <td>0.155518</td>\n",
       "      <td>-0.138541</td>\n",
       "      <td>-0.210777</td>\n",
       "      <td>0.210777</td>\n",
       "      <td>0.105374</td>\n",
       "      <td>-0.079156</td>\n",
       "      <td>-0.063690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.146812</td>\n",
       "      <td>-0.164661</td>\n",
       "      <td>-0.119633</td>\n",
       "      <td>-0.117303</td>\n",
       "      <td>-0.066992</td>\n",
       "      <td>-0.039600</td>\n",
       "      <td>-0.019636</td>\n",
       "      <td>0.126285</td>\n",
       "      <td>-0.027846</td>\n",
       "      <td>-0.119444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.085066</td>\n",
       "      <td>-0.050394</td>\n",
       "      <td>0.278442</td>\n",
       "      <td>0.085704</td>\n",
       "      <td>-0.085704</td>\n",
       "      <td>0.220451</td>\n",
       "      <td>-0.165600</td>\n",
       "      <td>-0.133244</td>\n",
       "      <td>-0.146812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.344483</td>\n",
       "      <td>-0.250282</td>\n",
       "      <td>-0.245406</td>\n",
       "      <td>-0.140153</td>\n",
       "      <td>-0.082846</td>\n",
       "      <td>-0.041080</td>\n",
       "      <td>0.154229</td>\n",
       "      <td>-0.058257</td>\n",
       "      <td>-0.140641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>-0.111087</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>0.220260</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>-0.011597</td>\n",
       "      <td>0.247252</td>\n",
       "      <td>-0.185733</td>\n",
       "      <td>-0.149443</td>\n",
       "      <td>-0.164661</td>\n",
       "      <td>-0.344483</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.280710</td>\n",
       "      <td>-0.275241</td>\n",
       "      <td>-0.157192</td>\n",
       "      <td>-0.092918</td>\n",
       "      <td>-0.046075</td>\n",
       "      <td>0.022545</td>\n",
       "      <td>0.169113</td>\n",
       "      <td>-0.058894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.067153</td>\n",
       "      <td>0.097199</td>\n",
       "      <td>-0.120913</td>\n",
       "      <td>0.061023</td>\n",
       "      <td>-0.061023</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>0.077483</td>\n",
       "      <td>-0.108577</td>\n",
       "      <td>-0.119633</td>\n",
       "      <td>-0.250282</td>\n",
       "      <td>-0.280710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.199974</td>\n",
       "      <td>-0.114207</td>\n",
       "      <td>-0.067509</td>\n",
       "      <td>-0.033475</td>\n",
       "      <td>0.060548</td>\n",
       "      <td>-0.047472</td>\n",
       "      <td>-0.049904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.057730</td>\n",
       "      <td>0.069318</td>\n",
       "      <td>-0.185130</td>\n",
       "      <td>-0.042134</td>\n",
       "      <td>0.042134</td>\n",
       "      <td>-0.081729</td>\n",
       "      <td>0.029109</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>-0.117303</td>\n",
       "      <td>-0.245406</td>\n",
       "      <td>-0.275241</td>\n",
       "      <td>-0.199974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.111982</td>\n",
       "      <td>-0.066194</td>\n",
       "      <td>-0.032823</td>\n",
       "      <td>-0.174436</td>\n",
       "      <td>-0.046547</td>\n",
       "      <td>0.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>-0.019268</td>\n",
       "      <td>-0.254816</td>\n",
       "      <td>-0.197038</td>\n",
       "      <td>-0.059340</td>\n",
       "      <td>0.059340</td>\n",
       "      <td>-0.635756</td>\n",
       "      <td>0.594906</td>\n",
       "      <td>0.242650</td>\n",
       "      <td>-0.066992</td>\n",
       "      <td>-0.140153</td>\n",
       "      <td>-0.157192</td>\n",
       "      <td>-0.114207</td>\n",
       "      <td>-0.111982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.037804</td>\n",
       "      <td>-0.018745</td>\n",
       "      <td>-0.187693</td>\n",
       "      <td>-0.026583</td>\n",
       "      <td>0.192194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>-0.054813</td>\n",
       "      <td>-0.200495</td>\n",
       "      <td>-0.127816</td>\n",
       "      <td>0.155319</td>\n",
       "      <td>-0.155319</td>\n",
       "      <td>-0.375805</td>\n",
       "      <td>-0.044668</td>\n",
       "      <td>0.621765</td>\n",
       "      <td>-0.039600</td>\n",
       "      <td>-0.082846</td>\n",
       "      <td>-0.092918</td>\n",
       "      <td>-0.067509</td>\n",
       "      <td>-0.066194</td>\n",
       "      <td>-0.037804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011081</td>\n",
       "      <td>-0.110948</td>\n",
       "      <td>-0.015714</td>\n",
       "      <td>0.113609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>-0.106131</td>\n",
       "      <td>0.044308</td>\n",
       "      <td>-0.042040</td>\n",
       "      <td>-0.071342</td>\n",
       "      <td>0.071342</td>\n",
       "      <td>0.029485</td>\n",
       "      <td>-0.022149</td>\n",
       "      <td>-0.017821</td>\n",
       "      <td>-0.019636</td>\n",
       "      <td>-0.041080</td>\n",
       "      <td>-0.046075</td>\n",
       "      <td>-0.033475</td>\n",
       "      <td>-0.032823</td>\n",
       "      <td>-0.018745</td>\n",
       "      <td>-0.011081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.055015</td>\n",
       "      <td>-0.007792</td>\n",
       "      <td>0.056334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.104870</td>\n",
       "      <td>0.085018</td>\n",
       "      <td>0.240382</td>\n",
       "      <td>0.062691</td>\n",
       "      <td>-0.062691</td>\n",
       "      <td>0.228733</td>\n",
       "      <td>-0.138522</td>\n",
       "      <td>-0.178440</td>\n",
       "      <td>0.126285</td>\n",
       "      <td>0.154229</td>\n",
       "      <td>0.022545</td>\n",
       "      <td>0.060548</td>\n",
       "      <td>-0.174436</td>\n",
       "      <td>-0.187693</td>\n",
       "      <td>-0.110948</td>\n",
       "      <td>-0.055015</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.078017</td>\n",
       "      <td>-0.976579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>-0.038544</td>\n",
       "      <td>0.019038</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>-0.004024</td>\n",
       "      <td>0.041814</td>\n",
       "      <td>-0.031410</td>\n",
       "      <td>-0.025273</td>\n",
       "      <td>-0.027846</td>\n",
       "      <td>-0.058257</td>\n",
       "      <td>0.169113</td>\n",
       "      <td>-0.047472</td>\n",
       "      <td>-0.046547</td>\n",
       "      <td>-0.026583</td>\n",
       "      <td>-0.015714</td>\n",
       "      <td>-0.007792</td>\n",
       "      <td>-0.078017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.138314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>-0.095861</td>\n",
       "      <td>-0.088568</td>\n",
       "      <td>-0.242172</td>\n",
       "      <td>-0.063146</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>-0.236252</td>\n",
       "      <td>0.144389</td>\n",
       "      <td>0.182720</td>\n",
       "      <td>-0.119444</td>\n",
       "      <td>-0.140641</td>\n",
       "      <td>-0.058894</td>\n",
       "      <td>-0.049904</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.192194</td>\n",
       "      <td>0.113609</td>\n",
       "      <td>0.056334</td>\n",
       "      <td>-0.976579</td>\n",
       "      <td>-0.138314</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived       Age      Fare    female      male         1  \\\n",
       "Survived  1.000000 -0.254085  0.134241  0.532418 -0.532418 -0.006668   \n",
       "Age      -0.254085  1.000000 -0.092424 -0.184969  0.184969  0.308880   \n",
       "Fare      0.134241 -0.092424  1.000000  0.130433 -0.130433  0.330206   \n",
       "female    0.532418 -0.184969  0.130433  1.000000 -1.000000 -0.062995   \n",
       "male     -0.532418  0.184969 -0.130433 -1.000000  1.000000  0.062995   \n",
       "1        -0.006668  0.308880  0.330206 -0.062995  0.062995  1.000000   \n",
       "2         0.081391 -0.199340 -0.236404  0.071243 -0.071243 -0.751190   \n",
       "3        -0.088158 -0.226143 -0.213634  0.009203 -0.009203 -0.604415   \n",
       "A        -0.050109  0.155518 -0.138541 -0.210777  0.210777  0.105374   \n",
       "B         0.085066 -0.050394  0.278442  0.085704 -0.085704  0.220451   \n",
       "C        -0.111087  0.016425  0.220260  0.011597 -0.011597  0.247252   \n",
       "D         0.067153  0.097199 -0.120913  0.061023 -0.061023  0.009967   \n",
       "E         0.057730  0.069318 -0.185130 -0.042134  0.042134 -0.081729   \n",
       "F        -0.019268 -0.254816 -0.197038 -0.059340  0.059340 -0.635756   \n",
       "G        -0.054813 -0.200495 -0.127816  0.155319 -0.155319 -0.375805   \n",
       "T        -0.106131  0.044308 -0.042040 -0.071342  0.071342  0.029485   \n",
       "C         0.104870  0.085018  0.240382  0.062691 -0.062691  0.228733   \n",
       "Q        -0.038544  0.019038  0.015625  0.004024 -0.004024  0.041814   \n",
       "S        -0.095861 -0.088568 -0.242172 -0.063146  0.063146 -0.236252   \n",
       "\n",
       "                 2         3         A         B         C         D  \\\n",
       "Survived  0.081391 -0.088158 -0.050109  0.085066 -0.111087  0.067153   \n",
       "Age      -0.199340 -0.226143  0.155518 -0.050394  0.016425  0.097199   \n",
       "Fare     -0.236404 -0.213634 -0.138541  0.278442  0.220260 -0.120913   \n",
       "female    0.071243  0.009203 -0.210777  0.085704  0.011597  0.061023   \n",
       "male     -0.071243 -0.009203  0.210777 -0.085704 -0.011597 -0.061023   \n",
       "1        -0.751190 -0.604415  0.105374  0.220451  0.247252  0.009967   \n",
       "2         1.000000 -0.071840 -0.079156 -0.165600 -0.185733  0.077483   \n",
       "3        -0.071840  1.000000 -0.063690 -0.133244 -0.149443 -0.108577   \n",
       "A        -0.079156 -0.063690  1.000000 -0.146812 -0.164661 -0.119633   \n",
       "B        -0.165600 -0.133244 -0.146812  1.000000 -0.344483 -0.250282   \n",
       "C        -0.185733 -0.149443 -0.164661 -0.344483  1.000000 -0.280710   \n",
       "D         0.077483 -0.108577 -0.119633 -0.250282 -0.280710  1.000000   \n",
       "E         0.029109  0.088363 -0.117303 -0.245406 -0.275241 -0.199974   \n",
       "F         0.594906  0.242650 -0.066992 -0.140153 -0.157192 -0.114207   \n",
       "G        -0.044668  0.621765 -0.039600 -0.082846 -0.092918 -0.067509   \n",
       "T        -0.022149 -0.017821 -0.019636 -0.041080 -0.046075 -0.033475   \n",
       "C        -0.138522 -0.178440  0.126285  0.154229  0.022545  0.060548   \n",
       "Q        -0.031410 -0.025273 -0.027846 -0.058257  0.169113 -0.047472   \n",
       "S         0.144389  0.182720 -0.119444 -0.140641 -0.058894 -0.049904   \n",
       "\n",
       "                 E         F         G         T         C         Q         S  \n",
       "Survived  0.057730 -0.019268 -0.054813 -0.106131  0.104870 -0.038544 -0.095861  \n",
       "Age       0.069318 -0.254816 -0.200495  0.044308  0.085018  0.019038 -0.088568  \n",
       "Fare     -0.185130 -0.197038 -0.127816 -0.042040  0.240382  0.015625 -0.242172  \n",
       "female   -0.042134 -0.059340  0.155319 -0.071342  0.062691  0.004024 -0.063146  \n",
       "male      0.042134  0.059340 -0.155319  0.071342 -0.062691 -0.004024  0.063146  \n",
       "1        -0.081729 -0.635756 -0.375805  0.029485  0.228733  0.041814 -0.236252  \n",
       "2         0.029109  0.594906 -0.044668 -0.022149 -0.138522 -0.031410  0.144389  \n",
       "3         0.088363  0.242650  0.621765 -0.017821 -0.178440 -0.025273  0.182720  \n",
       "A        -0.117303 -0.066992 -0.039600 -0.019636  0.126285 -0.027846 -0.119444  \n",
       "B        -0.245406 -0.140153 -0.082846 -0.041080  0.154229 -0.058257 -0.140641  \n",
       "C        -0.275241 -0.157192 -0.092918 -0.046075  0.022545  0.169113 -0.058894  \n",
       "D        -0.199974 -0.114207 -0.067509 -0.033475  0.060548 -0.047472 -0.049904  \n",
       "E         1.000000 -0.111982 -0.066194 -0.032823 -0.174436 -0.046547  0.183333  \n",
       "F        -0.111982  1.000000 -0.037804 -0.018745 -0.187693 -0.026583  0.192194  \n",
       "G        -0.066194 -0.037804  1.000000 -0.011081 -0.110948 -0.015714  0.113609  \n",
       "T        -0.032823 -0.018745 -0.011081  1.000000 -0.055015 -0.007792  0.056334  \n",
       "C        -0.174436 -0.187693 -0.110948 -0.055015  1.000000 -0.078017 -0.976579  \n",
       "Q        -0.046547 -0.026583 -0.015714 -0.007792 -0.078017  1.000000 -0.138314  \n",
       "S         0.183333  0.192194  0.113609  0.056334 -0.976579 -0.138314  1.000000  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Check the Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.48      0.57        25\n",
      "          1       0.70      0.86      0.78        36\n",
      "\n",
      "avg / total       0.71      0.70      0.69        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print classification_report(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. What do the classification metrics tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Check the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Dead</th>\n",
       "      <th>Predicted Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dead</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted Dead  Predicted Survived\n",
       "Dead                  12                  13\n",
       "Survived               5                  31"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "idx = ['Dead', 'Survived']\n",
    "col = ['Predicted Dead', 'Predicted Survived']\n",
    "cmdf = pd.DataFrame(cm, index=idx, columns=col)\n",
    "cmdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. What does the Confusion Matrix tell us? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is related to the low recall for the Survived class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Plot the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6kAAAMXCAYAAADYHxO2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1113259d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "Y_score = logreg.decision_function(X_test)\n",
    "\n",
    "FPR = dict()\n",
    "TPR = dict()\n",
    "ROC_AUC = dict()\n",
    "\n",
    "# For class 1, find the area under the curve\n",
    "FPR[1], TPR[1], _ = roc_curve(Y_test, Y_score)\n",
    "ROC_AUC[1] = auc(FPR[1], TPR[1])\n",
    "\n",
    "# Plot of a ROC curve for class 1\n",
    "plt.figure(figsize=[11,9])\n",
    "plt.plot(FPR[1], TPR[1], label='ROC curve (area = %0.2f)' % ROC_AUC[1], linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Acc', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. What does the ROC curve tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how accurate the model is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use GridSearchCV with logistic regression to search for optimal parameters \n",
    "\n",
    "- Use the provided parameter grid. Feel free to add if you like (such as n_jobs).\n",
    "- Use 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/ga-students/DSI-ATX-1/blob/master/curriculum/04-lessons/week-05/Feature_Selection_Lab/code/solution-code/solution-code-4_2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg_parameters = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'C':np.logspace(-5,1,50),\n",
    "    'solver':['liblinear']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Print out the best parameters and best score. Are they better than the vanilla logistic regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.19306977288832497, 'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GridSearchCV(LogisticRegression(),logreg_parameters)\n",
    "model.fit(X, y)\n",
    "\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Explain the difference between the difference between the L1 (Lasso) and L2 (Ridge) penalties on the model coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What hypothetical situations are the Ridge and Lasso penalties useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. [BONUS] Explain how the regularization strength (C) modifies the regression loss function. Why do the Ridge and Lasso penalties have their respective effects on the coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.a. [BONUS] You decide that you want to minimize false positives. Use the predicted probabilities from the model to set your threshold for labeling the positive class to need at least 90% confidence. How and why does this affect your confusion matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Gridsearch and kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Perform Gridsearch for the same classification problem as above, but use KNeighborsClassifier as your estimator\n",
    "\n",
    "At least have number of neighbors and weights in your parameters dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "params = {'n_neighbors': range(2,60)}\n",
    "\n",
    "gsknn = GridSearchCV(KNeighborsClassifier(),\n",
    "                     params, n_jobs=-1)\n",
    "gsknn.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Print the best parameters and score for the gridsearched kNN model. How does it compare to the logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params {'n_neighbors': 3}\n",
      "score 0.775956284153\n"
     ]
    }
   ],
   "source": [
    "print \"params\", gsknn.best_params_\n",
    "print \"score\", gsknn.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. How does the number of neighbors affect the bias-variance tradeoff of your model?\n",
    "\n",
    "#### [BONUS] Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. In what hypothetical scenario(s) might you prefer logistic regression over kNN, aside from model performance metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Fit a new kNN model with the optimal parameters found in gridsearch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=3, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_jobs=3)\n",
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Construct the confusion matrix for the optimal kNN model. Is it different from the logistic regression model? If so, how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Dead</th>\n",
       "      <th>Predicted Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dead</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted Dead  Predicted Survived\n",
       "Dead                  18                   7\n",
       "Survived               7                  29"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "idx = ['Dead', 'Survived']\n",
    "col = ['Predicted Dead', 'Predicted Survived']\n",
    "cmdf = pd.DataFrame(cm, index=idx, columns=col)\n",
    "cmdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. [BONUS] Plot the ROC curves for the optimized logistic regression model and the optimized kNN model on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: [BONUS] Precision-recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Gridsearch the same parameters for logistic regression but change the scoring function to 'average_precision'\n",
    "\n",
    "`'average_precision'` will optimize parameters for area under the precision-recall curve instead of for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Examine the best parameters and score. Are they different than the logistic regression gridsearch in part 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create the confusion matrix. Is it different than when you optimized for the accuracy? If so, why would this be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Plot the precision-recall curve. What does this tell us as opposed to the ROC curve?\n",
    "\n",
    "[See the sklearn plotting example here.](http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: [VERY BONUS] Decision trees, ensembles, bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Gridsearch a decision tree classifier model on the data, searching for optimal depth. Create a new decision tree model with the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compare the performace of the decision tree model to the logistic regression and kNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Plot all three optimized models' ROC curves on the same plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Use sklearn's BaggingClassifier with the base estimator your optimized decision tree model. How does the performance compare to the single decision tree classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Gridsearch the optimal n_estimators, max_samples, and max_features for the bagging classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Create a bagging classifier model with the optimal parameters and compare it's performance to the other two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dsienv]",
   "language": "python",
   "name": "conda-env-dsienv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
