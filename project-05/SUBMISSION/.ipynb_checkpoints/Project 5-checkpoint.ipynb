{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# http://localhost:8888/notebooks/Desktop/DSI-ATX-1/curriculum/04-lessons/week-05/2.4-lab/code/solution-code/solution-code-2_4.ipynb\n",
    "# http://localhost:8888/notebooks/Desktop/DSI-ATX-1/curriculum/04-lessons/week-05/2.3-lab/code/solution-code/solution-code-2_3.ipynb#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Task: Describe the goals of your study"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "survival        Survival\n",
    "                (0 = No; 1 = Yes)\n",
    "pclass          Passenger Class\n",
    "                (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "name            Name\n",
    "sex             Sex\n",
    "age             Age\n",
    "sibsp           Number of Siblings/Spouses Aboard\n",
    "parch           Number of Parents/Children Aboard\n",
    "ticket          Ticket Number\n",
    "fare            Passenger Fare\n",
    "cabin           Cabin\n",
    "embarked        Port of Embarkation\n",
    "                (C = Cherbourg; Q = Queenstown; S = Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Aquire the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Connect to the remote database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com/titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Query the database and aggregate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * FROM train', engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df.Survived,df.Pclass,df.Sex,df.Age,df.Fare,df.Cabin,df.Embarked], axis=1)\n",
    "df = df.dropna()\n",
    "df.Cabin = df.Cabin.apply(lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived  Pclass     Sex   Age     Fare Cabin Embarked\n",
       "1          1       1  female  38.0  71.2833     C        C\n",
       "3          1       1  female  35.0  53.1000     C        S\n",
       "6          0       1    male  54.0  51.8625     E        S\n",
       "10         1       3  female   4.0  16.7000     G        S\n",
       "11         1       1  female  58.0  26.5500     C        S"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What are the risks and assumptions of our data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all data is collected for every column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Describe the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      int64\n",
       "Pclass        int64\n",
       "Sex          object\n",
       "Age         float64\n",
       "Fare        float64\n",
       "Cabin        object\n",
       "Embarked     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived  Pclass     Sex   Age     Fare Cabin Embarked\n",
       "1          1       1  female  38.0  71.2833     C        C\n",
       "3          1       1  female  35.0  53.1000     C        S\n",
       "6          0       1    male  54.0  51.8625     E        S\n",
       "10         1       3  female   4.0  16.7000     G        S\n",
       "11         1       1  female  58.0  26.5500     C        S"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create Dummy Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.concat([df.Survived,df.Age,df.Fare],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating dummies [df.Sex,df.Pclass,df.Cabin,df.Embarked]\n",
    "\n",
    "dum = pd.get_dummies(df.Sex)\n",
    "df2 = pd.concat([df2,dum], axis=1) \n",
    "\n",
    "dum = pd.get_dummies(df.Pclass)\n",
    "df2 = pd.concat([df2,dum], axis=1)\n",
    "\n",
    "dum = pd.get_dummies(df.Cabin)\n",
    "df2 = pd.concat([df2,dum], axis=1) \n",
    "\n",
    "dum = pd.get_dummies(df.Embarked)\n",
    "df2 = pd.concat([df2,dum], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scaling \n",
    "from sklearn import preprocessing\n",
    "for i in df2.columns:\n",
    "    df2[i]=preprocessing.scale(df2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>T</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.698430</td>\n",
       "      <td>0.149065</td>\n",
       "      <td>-0.097180</td>\n",
       "      <td>1.039012</td>\n",
       "      <td>-1.039012</td>\n",
       "      <td>0.397779</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>-0.240424</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>1.608799</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>-0.149487</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>1.347362</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>-1.315805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698430</td>\n",
       "      <td>-0.043230</td>\n",
       "      <td>-0.335997</td>\n",
       "      <td>1.039012</td>\n",
       "      <td>-1.039012</td>\n",
       "      <td>0.397779</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>-0.240424</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>1.608799</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>-0.149487</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>-0.742191</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>0.759991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.431782</td>\n",
       "      <td>1.174636</td>\n",
       "      <td>-0.352250</td>\n",
       "      <td>-0.962453</td>\n",
       "      <td>0.962453</td>\n",
       "      <td>0.397779</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>-0.240424</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>-0.621582</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>2.258318</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>-0.149487</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>-0.742191</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>0.759991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.698430</td>\n",
       "      <td>-2.030273</td>\n",
       "      <td>-0.814070</td>\n",
       "      <td>1.039012</td>\n",
       "      <td>-1.039012</td>\n",
       "      <td>-2.513961</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>4.159327</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>-0.621582</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>6.689544</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>-0.742191</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>0.759991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.698430</td>\n",
       "      <td>1.431029</td>\n",
       "      <td>-0.684702</td>\n",
       "      <td>1.039012</td>\n",
       "      <td>-1.039012</td>\n",
       "      <td>0.397779</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>-0.240424</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>1.608799</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>-0.149487</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>-0.742191</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>0.759991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived       Age      Fare    female      male         1         2  \\\n",
       "1   0.698430  0.149065 -0.097180  1.039012 -1.039012  0.397779 -0.298807   \n",
       "3   0.698430 -0.043230 -0.335997  1.039012 -1.039012  0.397779 -0.298807   \n",
       "6  -1.431782  1.174636 -0.352250 -0.962453  0.962453  0.397779 -0.298807   \n",
       "10  0.698430 -2.030273 -0.814070  1.039012 -1.039012 -2.513961 -0.298807   \n",
       "11  0.698430  1.431029 -0.684702  1.039012 -1.039012  0.397779 -0.298807   \n",
       "\n",
       "           3         A         B         C         D         E        F  \\\n",
       "1  -0.240424 -0.264906 -0.554205  1.608799 -0.451605 -0.442807 -0.25289   \n",
       "3  -0.240424 -0.264906 -0.554205  1.608799 -0.451605 -0.442807 -0.25289   \n",
       "6  -0.240424 -0.264906 -0.554205 -0.621582 -0.451605  2.258318 -0.25289   \n",
       "10  4.159327 -0.264906 -0.554205 -0.621582 -0.451605 -0.442807 -0.25289   \n",
       "11 -0.240424 -0.264906 -0.554205  1.608799 -0.451605 -0.442807 -0.25289   \n",
       "\n",
       "           G         T         C         Q         S  \n",
       "1  -0.149487 -0.074125  1.347362 -0.105118 -1.315805  \n",
       "3  -0.149487 -0.074125 -0.742191 -0.105118  0.759991  \n",
       "6  -0.149487 -0.074125 -0.742191 -0.105118  0.759991  \n",
       "10  6.689544 -0.074125 -0.742191 -0.105118  0.759991  \n",
       "11 -0.149487 -0.074125 -0.742191 -0.105118  0.759991  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Logistic Regression and Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define the variables that we will use in our classification analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>T</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.149065</td>\n",
       "      <td>-0.097180</td>\n",
       "      <td>1.039012</td>\n",
       "      <td>-1.039012</td>\n",
       "      <td>0.397779</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>-0.240424</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>1.608799</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>-0.149487</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>1.347362</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>-1.315805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.043230</td>\n",
       "      <td>-0.335997</td>\n",
       "      <td>1.039012</td>\n",
       "      <td>-1.039012</td>\n",
       "      <td>0.397779</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>-0.240424</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>1.608799</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>-0.149487</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>-0.742191</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>0.759991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.174636</td>\n",
       "      <td>-0.352250</td>\n",
       "      <td>-0.962453</td>\n",
       "      <td>0.962453</td>\n",
       "      <td>0.397779</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>-0.240424</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>-0.621582</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>2.258318</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>-0.149487</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>-0.742191</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>0.759991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-2.030273</td>\n",
       "      <td>-0.814070</td>\n",
       "      <td>1.039012</td>\n",
       "      <td>-1.039012</td>\n",
       "      <td>-2.513961</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>4.159327</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>-0.621582</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>6.689544</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>-0.742191</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>0.759991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.431029</td>\n",
       "      <td>-0.684702</td>\n",
       "      <td>1.039012</td>\n",
       "      <td>-1.039012</td>\n",
       "      <td>0.397779</td>\n",
       "      <td>-0.298807</td>\n",
       "      <td>-0.240424</td>\n",
       "      <td>-0.264906</td>\n",
       "      <td>-0.554205</td>\n",
       "      <td>1.608799</td>\n",
       "      <td>-0.451605</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>-0.149487</td>\n",
       "      <td>-0.074125</td>\n",
       "      <td>-0.742191</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>0.759991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age      Fare    female      male         1         2         3  \\\n",
       "1   0.149065 -0.097180  1.039012 -1.039012  0.397779 -0.298807 -0.240424   \n",
       "3  -0.043230 -0.335997  1.039012 -1.039012  0.397779 -0.298807 -0.240424   \n",
       "6   1.174636 -0.352250 -0.962453  0.962453  0.397779 -0.298807 -0.240424   \n",
       "10 -2.030273 -0.814070  1.039012 -1.039012 -2.513961 -0.298807  4.159327   \n",
       "11  1.431029 -0.684702  1.039012 -1.039012  0.397779 -0.298807 -0.240424   \n",
       "\n",
       "           A         B         C         D         E        F         G  \\\n",
       "1  -0.264906 -0.554205  1.608799 -0.451605 -0.442807 -0.25289 -0.149487   \n",
       "3  -0.264906 -0.554205  1.608799 -0.451605 -0.442807 -0.25289 -0.149487   \n",
       "6  -0.264906 -0.554205 -0.621582 -0.451605  2.258318 -0.25289 -0.149487   \n",
       "10 -0.264906 -0.554205 -0.621582 -0.451605 -0.442807 -0.25289  6.689544   \n",
       "11 -0.264906 -0.554205  1.608799 -0.451605 -0.442807 -0.25289 -0.149487   \n",
       "\n",
       "           T         C         Q         S  \n",
       "1  -0.074125  1.347362 -0.105118 -1.315805  \n",
       "3  -0.074125 -0.742191 -0.105118  0.759991  \n",
       "6  -0.074125 -0.742191 -0.105118  0.759991  \n",
       "10 -0.074125 -0.742191 -0.105118  0.759991  \n",
       "11 -0.074125 -0.742191 -0.105118  0.759991  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "X = df2.iloc[:,1:]\n",
    "y = df[u'Survived']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Transform \"Y\" into a 1-Dimensional Array for SciKit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#????????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Conduct the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Examine the coefficients to see our correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>T</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.254085</td>\n",
       "      <td>0.134241</td>\n",
       "      <td>0.532418</td>\n",
       "      <td>-0.532418</td>\n",
       "      <td>-0.006668</td>\n",
       "      <td>0.081391</td>\n",
       "      <td>-0.088158</td>\n",
       "      <td>-0.050109</td>\n",
       "      <td>0.085066</td>\n",
       "      <td>-0.111087</td>\n",
       "      <td>0.067153</td>\n",
       "      <td>0.057730</td>\n",
       "      <td>-0.019268</td>\n",
       "      <td>-0.054813</td>\n",
       "      <td>-0.106131</td>\n",
       "      <td>0.104870</td>\n",
       "      <td>-0.038544</td>\n",
       "      <td>-0.095861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.254085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.092424</td>\n",
       "      <td>-0.184969</td>\n",
       "      <td>0.184969</td>\n",
       "      <td>0.308880</td>\n",
       "      <td>-0.199340</td>\n",
       "      <td>-0.226143</td>\n",
       "      <td>0.155518</td>\n",
       "      <td>-0.050394</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>0.097199</td>\n",
       "      <td>0.069318</td>\n",
       "      <td>-0.254816</td>\n",
       "      <td>-0.200495</td>\n",
       "      <td>0.044308</td>\n",
       "      <td>0.085018</td>\n",
       "      <td>0.019038</td>\n",
       "      <td>-0.088568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.134241</td>\n",
       "      <td>-0.092424</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.130433</td>\n",
       "      <td>-0.130433</td>\n",
       "      <td>0.330206</td>\n",
       "      <td>-0.236404</td>\n",
       "      <td>-0.213634</td>\n",
       "      <td>-0.138541</td>\n",
       "      <td>0.278442</td>\n",
       "      <td>0.220260</td>\n",
       "      <td>-0.120913</td>\n",
       "      <td>-0.185130</td>\n",
       "      <td>-0.197038</td>\n",
       "      <td>-0.127816</td>\n",
       "      <td>-0.042040</td>\n",
       "      <td>0.240382</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>-0.242172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.532418</td>\n",
       "      <td>-0.184969</td>\n",
       "      <td>0.130433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.062995</td>\n",
       "      <td>0.071243</td>\n",
       "      <td>0.009203</td>\n",
       "      <td>-0.210777</td>\n",
       "      <td>0.085704</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>0.061023</td>\n",
       "      <td>-0.042134</td>\n",
       "      <td>-0.059340</td>\n",
       "      <td>0.155319</td>\n",
       "      <td>-0.071342</td>\n",
       "      <td>0.062691</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>-0.063146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>-0.532418</td>\n",
       "      <td>0.184969</td>\n",
       "      <td>-0.130433</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062995</td>\n",
       "      <td>-0.071243</td>\n",
       "      <td>-0.009203</td>\n",
       "      <td>0.210777</td>\n",
       "      <td>-0.085704</td>\n",
       "      <td>-0.011597</td>\n",
       "      <td>-0.061023</td>\n",
       "      <td>0.042134</td>\n",
       "      <td>0.059340</td>\n",
       "      <td>-0.155319</td>\n",
       "      <td>0.071342</td>\n",
       "      <td>-0.062691</td>\n",
       "      <td>-0.004024</td>\n",
       "      <td>0.063146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006668</td>\n",
       "      <td>0.308880</td>\n",
       "      <td>0.330206</td>\n",
       "      <td>-0.062995</td>\n",
       "      <td>0.062995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.751190</td>\n",
       "      <td>-0.604415</td>\n",
       "      <td>0.105374</td>\n",
       "      <td>0.220451</td>\n",
       "      <td>0.247252</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>-0.081729</td>\n",
       "      <td>-0.635756</td>\n",
       "      <td>-0.375805</td>\n",
       "      <td>0.029485</td>\n",
       "      <td>0.228733</td>\n",
       "      <td>0.041814</td>\n",
       "      <td>-0.236252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.081391</td>\n",
       "      <td>-0.199340</td>\n",
       "      <td>-0.236404</td>\n",
       "      <td>0.071243</td>\n",
       "      <td>-0.071243</td>\n",
       "      <td>-0.751190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.071840</td>\n",
       "      <td>-0.079156</td>\n",
       "      <td>-0.165600</td>\n",
       "      <td>-0.185733</td>\n",
       "      <td>0.077483</td>\n",
       "      <td>0.029109</td>\n",
       "      <td>0.594906</td>\n",
       "      <td>-0.044668</td>\n",
       "      <td>-0.022149</td>\n",
       "      <td>-0.138522</td>\n",
       "      <td>-0.031410</td>\n",
       "      <td>0.144389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.088158</td>\n",
       "      <td>-0.226143</td>\n",
       "      <td>-0.213634</td>\n",
       "      <td>0.009203</td>\n",
       "      <td>-0.009203</td>\n",
       "      <td>-0.604415</td>\n",
       "      <td>-0.071840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.063690</td>\n",
       "      <td>-0.133244</td>\n",
       "      <td>-0.149443</td>\n",
       "      <td>-0.108577</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>0.242650</td>\n",
       "      <td>0.621765</td>\n",
       "      <td>-0.017821</td>\n",
       "      <td>-0.178440</td>\n",
       "      <td>-0.025273</td>\n",
       "      <td>0.182720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>-0.050109</td>\n",
       "      <td>0.155518</td>\n",
       "      <td>-0.138541</td>\n",
       "      <td>-0.210777</td>\n",
       "      <td>0.210777</td>\n",
       "      <td>0.105374</td>\n",
       "      <td>-0.079156</td>\n",
       "      <td>-0.063690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.146812</td>\n",
       "      <td>-0.164661</td>\n",
       "      <td>-0.119633</td>\n",
       "      <td>-0.117303</td>\n",
       "      <td>-0.066992</td>\n",
       "      <td>-0.039600</td>\n",
       "      <td>-0.019636</td>\n",
       "      <td>0.126285</td>\n",
       "      <td>-0.027846</td>\n",
       "      <td>-0.119444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.085066</td>\n",
       "      <td>-0.050394</td>\n",
       "      <td>0.278442</td>\n",
       "      <td>0.085704</td>\n",
       "      <td>-0.085704</td>\n",
       "      <td>0.220451</td>\n",
       "      <td>-0.165600</td>\n",
       "      <td>-0.133244</td>\n",
       "      <td>-0.146812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.344483</td>\n",
       "      <td>-0.250282</td>\n",
       "      <td>-0.245406</td>\n",
       "      <td>-0.140153</td>\n",
       "      <td>-0.082846</td>\n",
       "      <td>-0.041080</td>\n",
       "      <td>0.154229</td>\n",
       "      <td>-0.058257</td>\n",
       "      <td>-0.140641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>-0.111087</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>0.220260</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>-0.011597</td>\n",
       "      <td>0.247252</td>\n",
       "      <td>-0.185733</td>\n",
       "      <td>-0.149443</td>\n",
       "      <td>-0.164661</td>\n",
       "      <td>-0.344483</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.280710</td>\n",
       "      <td>-0.275241</td>\n",
       "      <td>-0.157192</td>\n",
       "      <td>-0.092918</td>\n",
       "      <td>-0.046075</td>\n",
       "      <td>0.022545</td>\n",
       "      <td>0.169113</td>\n",
       "      <td>-0.058894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.067153</td>\n",
       "      <td>0.097199</td>\n",
       "      <td>-0.120913</td>\n",
       "      <td>0.061023</td>\n",
       "      <td>-0.061023</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>0.077483</td>\n",
       "      <td>-0.108577</td>\n",
       "      <td>-0.119633</td>\n",
       "      <td>-0.250282</td>\n",
       "      <td>-0.280710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.199974</td>\n",
       "      <td>-0.114207</td>\n",
       "      <td>-0.067509</td>\n",
       "      <td>-0.033475</td>\n",
       "      <td>0.060548</td>\n",
       "      <td>-0.047472</td>\n",
       "      <td>-0.049904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.057730</td>\n",
       "      <td>0.069318</td>\n",
       "      <td>-0.185130</td>\n",
       "      <td>-0.042134</td>\n",
       "      <td>0.042134</td>\n",
       "      <td>-0.081729</td>\n",
       "      <td>0.029109</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>-0.117303</td>\n",
       "      <td>-0.245406</td>\n",
       "      <td>-0.275241</td>\n",
       "      <td>-0.199974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.111982</td>\n",
       "      <td>-0.066194</td>\n",
       "      <td>-0.032823</td>\n",
       "      <td>-0.174436</td>\n",
       "      <td>-0.046547</td>\n",
       "      <td>0.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>-0.019268</td>\n",
       "      <td>-0.254816</td>\n",
       "      <td>-0.197038</td>\n",
       "      <td>-0.059340</td>\n",
       "      <td>0.059340</td>\n",
       "      <td>-0.635756</td>\n",
       "      <td>0.594906</td>\n",
       "      <td>0.242650</td>\n",
       "      <td>-0.066992</td>\n",
       "      <td>-0.140153</td>\n",
       "      <td>-0.157192</td>\n",
       "      <td>-0.114207</td>\n",
       "      <td>-0.111982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.037804</td>\n",
       "      <td>-0.018745</td>\n",
       "      <td>-0.187693</td>\n",
       "      <td>-0.026583</td>\n",
       "      <td>0.192194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>-0.054813</td>\n",
       "      <td>-0.200495</td>\n",
       "      <td>-0.127816</td>\n",
       "      <td>0.155319</td>\n",
       "      <td>-0.155319</td>\n",
       "      <td>-0.375805</td>\n",
       "      <td>-0.044668</td>\n",
       "      <td>0.621765</td>\n",
       "      <td>-0.039600</td>\n",
       "      <td>-0.082846</td>\n",
       "      <td>-0.092918</td>\n",
       "      <td>-0.067509</td>\n",
       "      <td>-0.066194</td>\n",
       "      <td>-0.037804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011081</td>\n",
       "      <td>-0.110948</td>\n",
       "      <td>-0.015714</td>\n",
       "      <td>0.113609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>-0.106131</td>\n",
       "      <td>0.044308</td>\n",
       "      <td>-0.042040</td>\n",
       "      <td>-0.071342</td>\n",
       "      <td>0.071342</td>\n",
       "      <td>0.029485</td>\n",
       "      <td>-0.022149</td>\n",
       "      <td>-0.017821</td>\n",
       "      <td>-0.019636</td>\n",
       "      <td>-0.041080</td>\n",
       "      <td>-0.046075</td>\n",
       "      <td>-0.033475</td>\n",
       "      <td>-0.032823</td>\n",
       "      <td>-0.018745</td>\n",
       "      <td>-0.011081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.055015</td>\n",
       "      <td>-0.007792</td>\n",
       "      <td>0.056334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.104870</td>\n",
       "      <td>0.085018</td>\n",
       "      <td>0.240382</td>\n",
       "      <td>0.062691</td>\n",
       "      <td>-0.062691</td>\n",
       "      <td>0.228733</td>\n",
       "      <td>-0.138522</td>\n",
       "      <td>-0.178440</td>\n",
       "      <td>0.126285</td>\n",
       "      <td>0.154229</td>\n",
       "      <td>0.022545</td>\n",
       "      <td>0.060548</td>\n",
       "      <td>-0.174436</td>\n",
       "      <td>-0.187693</td>\n",
       "      <td>-0.110948</td>\n",
       "      <td>-0.055015</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.078017</td>\n",
       "      <td>-0.976579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>-0.038544</td>\n",
       "      <td>0.019038</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>-0.004024</td>\n",
       "      <td>0.041814</td>\n",
       "      <td>-0.031410</td>\n",
       "      <td>-0.025273</td>\n",
       "      <td>-0.027846</td>\n",
       "      <td>-0.058257</td>\n",
       "      <td>0.169113</td>\n",
       "      <td>-0.047472</td>\n",
       "      <td>-0.046547</td>\n",
       "      <td>-0.026583</td>\n",
       "      <td>-0.015714</td>\n",
       "      <td>-0.007792</td>\n",
       "      <td>-0.078017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.138314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>-0.095861</td>\n",
       "      <td>-0.088568</td>\n",
       "      <td>-0.242172</td>\n",
       "      <td>-0.063146</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>-0.236252</td>\n",
       "      <td>0.144389</td>\n",
       "      <td>0.182720</td>\n",
       "      <td>-0.119444</td>\n",
       "      <td>-0.140641</td>\n",
       "      <td>-0.058894</td>\n",
       "      <td>-0.049904</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.192194</td>\n",
       "      <td>0.113609</td>\n",
       "      <td>0.056334</td>\n",
       "      <td>-0.976579</td>\n",
       "      <td>-0.138314</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived       Age      Fare    female      male         1  \\\n",
       "Survived  1.000000 -0.254085  0.134241  0.532418 -0.532418 -0.006668   \n",
       "Age      -0.254085  1.000000 -0.092424 -0.184969  0.184969  0.308880   \n",
       "Fare      0.134241 -0.092424  1.000000  0.130433 -0.130433  0.330206   \n",
       "female    0.532418 -0.184969  0.130433  1.000000 -1.000000 -0.062995   \n",
       "male     -0.532418  0.184969 -0.130433 -1.000000  1.000000  0.062995   \n",
       "1        -0.006668  0.308880  0.330206 -0.062995  0.062995  1.000000   \n",
       "2         0.081391 -0.199340 -0.236404  0.071243 -0.071243 -0.751190   \n",
       "3        -0.088158 -0.226143 -0.213634  0.009203 -0.009203 -0.604415   \n",
       "A        -0.050109  0.155518 -0.138541 -0.210777  0.210777  0.105374   \n",
       "B         0.085066 -0.050394  0.278442  0.085704 -0.085704  0.220451   \n",
       "C        -0.111087  0.016425  0.220260  0.011597 -0.011597  0.247252   \n",
       "D         0.067153  0.097199 -0.120913  0.061023 -0.061023  0.009967   \n",
       "E         0.057730  0.069318 -0.185130 -0.042134  0.042134 -0.081729   \n",
       "F        -0.019268 -0.254816 -0.197038 -0.059340  0.059340 -0.635756   \n",
       "G        -0.054813 -0.200495 -0.127816  0.155319 -0.155319 -0.375805   \n",
       "T        -0.106131  0.044308 -0.042040 -0.071342  0.071342  0.029485   \n",
       "C         0.104870  0.085018  0.240382  0.062691 -0.062691  0.228733   \n",
       "Q        -0.038544  0.019038  0.015625  0.004024 -0.004024  0.041814   \n",
       "S        -0.095861 -0.088568 -0.242172 -0.063146  0.063146 -0.236252   \n",
       "\n",
       "                 2         3         A         B         C         D  \\\n",
       "Survived  0.081391 -0.088158 -0.050109  0.085066 -0.111087  0.067153   \n",
       "Age      -0.199340 -0.226143  0.155518 -0.050394  0.016425  0.097199   \n",
       "Fare     -0.236404 -0.213634 -0.138541  0.278442  0.220260 -0.120913   \n",
       "female    0.071243  0.009203 -0.210777  0.085704  0.011597  0.061023   \n",
       "male     -0.071243 -0.009203  0.210777 -0.085704 -0.011597 -0.061023   \n",
       "1        -0.751190 -0.604415  0.105374  0.220451  0.247252  0.009967   \n",
       "2         1.000000 -0.071840 -0.079156 -0.165600 -0.185733  0.077483   \n",
       "3        -0.071840  1.000000 -0.063690 -0.133244 -0.149443 -0.108577   \n",
       "A        -0.079156 -0.063690  1.000000 -0.146812 -0.164661 -0.119633   \n",
       "B        -0.165600 -0.133244 -0.146812  1.000000 -0.344483 -0.250282   \n",
       "C        -0.185733 -0.149443 -0.164661 -0.344483  1.000000 -0.280710   \n",
       "D         0.077483 -0.108577 -0.119633 -0.250282 -0.280710  1.000000   \n",
       "E         0.029109  0.088363 -0.117303 -0.245406 -0.275241 -0.199974   \n",
       "F         0.594906  0.242650 -0.066992 -0.140153 -0.157192 -0.114207   \n",
       "G        -0.044668  0.621765 -0.039600 -0.082846 -0.092918 -0.067509   \n",
       "T        -0.022149 -0.017821 -0.019636 -0.041080 -0.046075 -0.033475   \n",
       "C        -0.138522 -0.178440  0.126285  0.154229  0.022545  0.060548   \n",
       "Q        -0.031410 -0.025273 -0.027846 -0.058257  0.169113 -0.047472   \n",
       "S         0.144389  0.182720 -0.119444 -0.140641 -0.058894 -0.049904   \n",
       "\n",
       "                 E         F         G         T         C         Q         S  \n",
       "Survived  0.057730 -0.019268 -0.054813 -0.106131  0.104870 -0.038544 -0.095861  \n",
       "Age       0.069318 -0.254816 -0.200495  0.044308  0.085018  0.019038 -0.088568  \n",
       "Fare     -0.185130 -0.197038 -0.127816 -0.042040  0.240382  0.015625 -0.242172  \n",
       "female   -0.042134 -0.059340  0.155319 -0.071342  0.062691  0.004024 -0.063146  \n",
       "male      0.042134  0.059340 -0.155319  0.071342 -0.062691 -0.004024  0.063146  \n",
       "1        -0.081729 -0.635756 -0.375805  0.029485  0.228733  0.041814 -0.236252  \n",
       "2         0.029109  0.594906 -0.044668 -0.022149 -0.138522 -0.031410  0.144389  \n",
       "3         0.088363  0.242650  0.621765 -0.017821 -0.178440 -0.025273  0.182720  \n",
       "A        -0.117303 -0.066992 -0.039600 -0.019636  0.126285 -0.027846 -0.119444  \n",
       "B        -0.245406 -0.140153 -0.082846 -0.041080  0.154229 -0.058257 -0.140641  \n",
       "C        -0.275241 -0.157192 -0.092918 -0.046075  0.022545  0.169113 -0.058894  \n",
       "D        -0.199974 -0.114207 -0.067509 -0.033475  0.060548 -0.047472 -0.049904  \n",
       "E         1.000000 -0.111982 -0.066194 -0.032823 -0.174436 -0.046547  0.183333  \n",
       "F        -0.111982  1.000000 -0.037804 -0.018745 -0.187693 -0.026583  0.192194  \n",
       "G        -0.066194 -0.037804  1.000000 -0.011081 -0.110948 -0.015714  0.113609  \n",
       "T        -0.032823 -0.018745 -0.011081  1.000000 -0.055015 -0.007792  0.056334  \n",
       "C        -0.174436 -0.187693 -0.110948 -0.055015  1.000000 -0.078017 -0.976579  \n",
       "Q        -0.046547 -0.026583 -0.015714 -0.007792 -0.078017  1.000000 -0.138314  \n",
       "S         0.183333  0.192194  0.113609  0.056334 -0.976579 -0.138314  1.000000  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Test the Model by introducing a *Test* or *Validaton* set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=5, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=5)\n",
    "logreg.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Predict the class labels for the *Test* set   ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Predict the class probabilities for the *Test* set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35486196,  0.64513804],\n",
       "       [ 0.73421042,  0.26578958],\n",
       "       [ 0.02842001,  0.97157999],\n",
       "       [ 0.17108434,  0.82891566],\n",
       "       [ 0.0128808 ,  0.9871192 ],\n",
       "       [ 0.03451531,  0.96548469],\n",
       "       [ 0.16430174,  0.83569826],\n",
       "       [ 0.39908285,  0.60091715],\n",
       "       [ 0.10781854,  0.89218146],\n",
       "       [ 0.70816109,  0.29183891],\n",
       "       [ 0.32254387,  0.67745613],\n",
       "       [ 0.59388076,  0.40611924],\n",
       "       [ 0.45135779,  0.54864221],\n",
       "       [ 0.02008495,  0.97991505],\n",
       "       [ 0.90466176,  0.09533824],\n",
       "       [ 0.69857042,  0.30142958],\n",
       "       [ 0.36472454,  0.63527546],\n",
       "       [ 0.12673852,  0.87326148],\n",
       "       [ 0.42402205,  0.57597795],\n",
       "       [ 0.12245459,  0.87754541],\n",
       "       [ 0.10887793,  0.89112207],\n",
       "       [ 0.71814378,  0.28185622],\n",
       "       [ 0.70196854,  0.29803146],\n",
       "       [ 0.42449716,  0.57550284],\n",
       "       [ 0.08727287,  0.91272713],\n",
       "       [ 0.01359177,  0.98640823],\n",
       "       [ 0.0615398 ,  0.9384602 ],\n",
       "       [ 0.4208022 ,  0.5791978 ],\n",
       "       [ 0.47517246,  0.52482754],\n",
       "       [ 0.02988734,  0.97011266],\n",
       "       [ 0.2632627 ,  0.7367373 ],\n",
       "       [ 0.03555181,  0.96444819],\n",
       "       [ 0.22750442,  0.77249558],\n",
       "       [ 0.6175465 ,  0.3824535 ],\n",
       "       [ 0.49588445,  0.50411555],\n",
       "       [ 0.78544291,  0.21455709],\n",
       "       [ 0.13551127,  0.86448873],\n",
       "       [ 0.0097366 ,  0.9902634 ],\n",
       "       [ 0.12468183,  0.87531817],\n",
       "       [ 0.04526533,  0.95473467],\n",
       "       [ 0.43377909,  0.56622091],\n",
       "       [ 0.05230564,  0.94769436],\n",
       "       [ 0.74432976,  0.25567024],\n",
       "       [ 0.50163589,  0.49836411],\n",
       "       [ 0.37067608,  0.62932392],\n",
       "       [ 0.84335425,  0.15664575],\n",
       "       [ 0.64512373,  0.35487627],\n",
       "       [ 0.58470834,  0.41529166],\n",
       "       [ 0.02713163,  0.97286837],\n",
       "       [ 0.0352239 ,  0.9647761 ],\n",
       "       [ 0.61968888,  0.38031112],\n",
       "       [ 0.44376054,  0.55623946],\n",
       "       [ 0.45399035,  0.54600965],\n",
       "       [ 0.03545811,  0.96454189],\n",
       "       [ 0.88021029,  0.11978971],\n",
       "       [ 0.02779165,  0.97220835],\n",
       "       [ 0.24497879,  0.75502121],\n",
       "       [ 0.01163462,  0.98836538],\n",
       "       [ 0.06465117,  0.93534883],\n",
       "       [ 0.3930714 ,  0.6069286 ],\n",
       "       [ 0.59007424,  0.40992576]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Evaluate the *Test* set ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Survived',      u'Age',     u'Fare',   u'female',     u'male',\n",
       "                 1,           2,           3,        u'A',        u'B',\n",
       "              u'C',        u'D',        u'E',        u'F',        u'G',\n",
       "              u'T',        u'C',        u'Q',        u'S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Cross validate the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.671212121212\n"
     ]
    }
   ],
   "source": [
    "# use cross-validation for find score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# Perform 6-fold cross validation\n",
    "logreg_scores = cross_val_score(logreg,X_test, Y_test, cv=6, scoring = 'accuracy')\n",
    "print logreg_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Check the Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.48      0.57        25\n",
      "          1       0.70      0.86      0.78        36\n",
      "\n",
      "avg / total       0.71      0.70      0.69        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "logreg_class = classification_report(Y_test, y_pred)\n",
    "print logreg_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. What do the classification metrics tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Check the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Dead</th>\n",
       "      <th>Predicted Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dead</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted Dead  Predicted Survived\n",
       "Dead                  12                  13\n",
       "Survived               5                  31"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "idx = ['Dead', 'Survived']\n",
    "col = ['Predicted Dead', 'Predicted Survived']\n",
    "logreg_cmdf = pd.DataFrame(cm, index=idx, columns=col)\n",
    "logreg_cmdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. What does the Confusion Matrix tell us? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is related to the low recall for the Survived class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Plot the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6kAAAMXCAYAAADYHxO2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDSWpIiIiIiIiUmj8f5ZKNmyGOkUyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1113d71d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "Y_score = logreg.decision_function(X_test)\n",
    "\n",
    "FPR = dict()\n",
    "TPR = dict()\n",
    "ROC_AUC = dict()\n",
    "\n",
    "# For class 1, find the area under the curve\n",
    "FPR[1], TPR[1], _ = roc_curve(Y_test, Y_score)\n",
    "ROC_AUC[1] = auc(FPR[1], TPR[1])\n",
    "\n",
    "# Plot of a ROC curve for class 1\n",
    "plt.figure(figsize=[11,9])\n",
    "plt.plot(FPR[1], TPR[1], label='ROC curve (area = %0.2f)' % ROC_AUC[1], linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Accuracy', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. What does the ROC curve tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how accurate the model is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use GridSearchCV with logistic regression to search for optimal parameters \n",
    "\n",
    "- Use the provided parameter grid. Feel free to add if you like (such as n_jobs).\n",
    "- Use 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/ga-students/DSI-ATX-1/blob/master/curriculum/04-lessons/week-05/Feature_Selection_Lab/code/solution-code/solution-code-4_2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg_parameters = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'C':np.logspace(-5,1,50),\n",
    "    'solver':['liblinear']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Print out the best parameters and best score. Are they better than the vanilla logistic regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': array([  1.00000e-05,   1.32571e-05,   1.75751e-05,   2.32995e-05,\n",
       "         3.08884e-05,   4.09492e-05,   5.42868e-05,   7.19686e-05,\n",
       "         9.54095e-05,   1.26486e-04,   1.67683e-04,   2.22300e-04,\n",
       "         2.94705e-04,   3.90694e-04,   5.17947e-04,   6.8...6e+00,   4.29193e+00,   5.68987e+00,\n",
       "         7.54312e+00,   1.00000e+01]), 'solver': ['liblinear']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GridSearchCV(LogisticRegression(),logreg_parameters)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params {'penalty': 'l1', 'C': 0.19306977288832497, 'solver': 'liblinear'}\n",
      "score 0.765027322404\n"
     ]
    }
   ],
   "source": [
    "print \"params\", model.best_params_\n",
    "print \"score\", model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit best params\n",
    "model = LogisticRegression(penalty= 'l1', C= 0.19306977288832497, solver= 'liblinear')\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.737878787879\n"
     ]
    }
   ],
   "source": [
    "# Perform 6-fold cross validation\n",
    "gridlogreg_scores = cross_val_score(model,X_test, Y_test, cv=6, scoring = 'accuracy')\n",
    "print gridlogreg_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.80      0.77        25\n",
      "          1       0.85      0.81      0.83        36\n",
      "\n",
      "avg / total       0.81      0.80      0.80        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class report\n",
    "gridlogreg_class= classification_report(Y_test, y_pred)\n",
    "print gridlogreg_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Dead</th>\n",
       "      <th>Predicted Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dead</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted Dead  Predicted Survived\n",
       "Dead                  20                   5\n",
       "Survived               7                  29"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "idx = ['Dead', 'Survived']\n",
    "col = ['Predicted Dead', 'Predicted Survived']\n",
    "gridlogreg_cmdf = pd.DataFrame(cm, index=idx, columns=col)\n",
    "gridlogreg_cmdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Explain the difference between the difference between the L1 (Lasso) and L2 (Ridge) penalties on the model coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 - uses min and max\n",
    "L2 - uses mean and standard dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What hypothetical situations are the Ridge and Lasso penalties useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When model is overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. [BONUS] Explain how the regularization strength (C) modifies the regression loss function. Why do the Ridge and Lasso penalties have their respective effects on the coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.a. [BONUS] You decide that you want to minimize false positives. Use the predicted probabilities from the model to set your threshold for labeling the positive class to need at least 90% confidence. How and why does this affect your confusion matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Gridsearch and kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Perform Gridsearch for the same classification problem as above, but use KNeighborsClassifier as your estimator\n",
    "\n",
    "At least have number of neighbors and weights in your parameters dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X,y)\n",
    "\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.656060606061\n"
     ]
    }
   ],
   "source": [
    "# Perform 6-fold cross validation\n",
    "knn_scores = cross_val_score(knn,X_test, Y_test, cv=6, scoring = 'accuracy')\n",
    "print knn_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.72      0.72        25\n",
      "          1       0.81      0.81      0.81        36\n",
      "\n",
      "avg / total       0.77      0.77      0.77        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class report\n",
    "knn_class= classification_report(Y_test, y_pred)\n",
    "print knn_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Dead</th>\n",
       "      <th>Predicted Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dead</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted Dead  Predicted Survived\n",
       "Dead                  18                   7\n",
       "Survived               7                  29"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion_matrix\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "idx = ['Dead', 'Survived']\n",
    "col = ['Predicted Dead', 'Predicted Survived']\n",
    "knn_cmdf = pd.DataFrame(cm, index=idx, columns=col)\n",
    "knn_cmdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KNN GRIDSEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "params = {'n_neighbors': range(2,50)}\n",
    "\n",
    "gsknn = GridSearchCV(KNeighborsClassifier(),\n",
    "                     params, n_jobs=-1)\n",
    "gsknn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Print the best parameters and score for the gridsearched kNN model. How does it compare to the logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params {'n_neighbors': 3}\n",
      "score 0.775956284153\n"
     ]
    }
   ],
   "source": [
    "print \"params\", gsknn.best_params_\n",
    "print \"score\", gsknn.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. How does the number of neighbors affect the bias-variance tradeoff of your model?\n",
    "\n",
    "#### [BONUS] Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. In what hypothetical scenario(s) might you prefer logistic regression over kNN, aside from model performance metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Fit a new kNN model with the optimal parameters found in gridsearch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X,y)\n",
    "\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Construct the confusion matrix for the optimal kNN model. Is it different from the logistic regression model? If so, how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70303030303\n"
     ]
    }
   ],
   "source": [
    "# Perform 6-fold cross validation\n",
    "gridknn_scores = cross_val_score(knn,X_test, Y_test, cv=6, scoring = 'accuracy')\n",
    "print gridknn_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.76      0.76        25\n",
      "          1       0.83      0.83      0.83        36\n",
      "\n",
      "avg / total       0.80      0.80      0.80        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class report\n",
    "gridknn_class= classification_report(Y_test, y_pred)\n",
    "print gridknn_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Dead</th>\n",
       "      <th>Predicted Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dead</th>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted Dead  Predicted Survived\n",
       "Dead                  19                   6\n",
       "Survived               6                  30"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "idx = ['Dead', 'Survived']\n",
    "col = ['Predicted Dead', 'Predicted Survived']\n",
    "gridknn_cmdf = pd.DataFrame(cm, index=idx, columns=col)\n",
    "gridknn_cmdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Reg Score 0.671212121212\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.48      0.57        25\n",
      "          1       0.70      0.86      0.78        36\n",
      "\n",
      "avg / total       0.71      0.70      0.69        61\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Dead</th>\n",
       "      <th>Predicted Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dead</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted Dead  Predicted Survived\n",
       "Dead                  12                  13\n",
       "Survived               5                  31"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log Regression\n",
    "print \"Log Reg Score\",logreg_scores.mean()\n",
    "print logreg_class\n",
    "logreg_cmdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Log Reg Score 0.737878787879\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.80      0.77        25\n",
      "          1       0.85      0.81      0.83        36\n",
      "\n",
      "avg / total       0.81      0.80      0.80        61\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Dead</th>\n",
       "      <th>Predicted Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dead</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted Dead  Predicted Survived\n",
       "Dead                  20                   5\n",
       "Survived               7                  29"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log Regression Grid\n",
    "print \"Grid Log Reg Score\",gridlogreg_scores.mean()\n",
    "print gridlogreg_class\n",
    "gridlogreg_cmdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Score 0.656060606061\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.72      0.72        25\n",
      "          1       0.81      0.81      0.81        36\n",
      "\n",
      "avg / total       0.77      0.77      0.77        61\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Dead</th>\n",
       "      <th>Predicted Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dead</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted Dead  Predicted Survived\n",
       "Dead                  18                   7\n",
       "Survived               7                  29"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN\n",
    "print \"KNN Score\",knn_scores.mean()\n",
    "print knn_class\n",
    "knn_cmdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid KNN Score 0.70303030303\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.76      0.76        25\n",
      "          1       0.83      0.83      0.83        36\n",
      "\n",
      "avg / total       0.80      0.80      0.80        61\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Dead</th>\n",
       "      <th>Predicted Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dead</th>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted Dead  Predicted Survived\n",
       "Dead                  19                   6\n",
       "Survived               6                  30"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRID KNN\n",
    "print \"Grid KNN Score\",gridknn_scores.mean()\n",
    "print gridknn_class\n",
    "gridknn_cmdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. [BONUS] Plot the ROC curves for the optimized logistic regression model and the optimized kNN model on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_curve, auc\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.style.use('seaborn-white')\n",
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "# Y_score = logreg.decision_function(X_test)\n",
    "\n",
    "# FPR = dict()\n",
    "# TPR = dict()\n",
    "# ROC_AUC = dict()\n",
    "\n",
    "# # For class 1, find the area under the curve\n",
    "# FPR[1], TPR[1], _ = roc_curve(Y_test, Y_score)\n",
    "# ROC_AUC[1] = auc(FPR[1], TPR[1])\n",
    "\n",
    "# # Plot of a ROC curve for class 1\n",
    "# plt.figure(figsize=[11,9])\n",
    "# plt.plot(FPR[1], TPR[1], label='ROC curve (area = %0.2f)' % ROC_AUC[1], linewidth=4)\n",
    "# plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate', fontsize=18)\n",
    "# plt.ylabel('True Positive Rate', fontsize=18)\n",
    "# plt.title('Accuracy', fontsize=18)\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: [BONUS] Precision-recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Gridsearch the same parameters for logistic regression but change the scoring function to 'average_precision'\n",
    "\n",
    "`'average_precision'` will optimize parameters for area under the precision-recall curve instead of for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Examine the best parameters and score. Are they different than the logistic regression gridsearch in part 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create the confusion matrix. Is it different than when you optimized for the accuracy? If so, why would this be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Plot the precision-recall curve. What does this tell us as opposed to the ROC curve?\n",
    "\n",
    "[See the sklearn plotting example here.](http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: [VERY BONUS] Decision trees, ensembles, bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Gridsearch a decision tree classifier model on the data, searching for optimal depth. Create a new decision tree model with the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compare the performace of the decision tree model to the logistic regression and kNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Plot all three optimized models' ROC curves on the same plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Use sklearn's BaggingClassifier with the base estimator your optimized decision tree model. How does the performance compare to the single decision tree classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Gridsearch the optimal n_estimators, max_samples, and max_features for the bagging classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Create a bagging classifier model with the optimal parameters and compare it's performance to the other two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dsienv]",
   "language": "python",
   "name": "conda-env-dsienv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
